Solve a bug.
Diagnosis what goes wrong? 

$kubectl get pods
NAME                             READY   STATUS                       RESTARTS   AGE
cat-facts-app-5fc888646c-5m6zh   0/1     CreateContainerConfigError   0          9m33s

$kubectl describe pod cat-facts-app-5fc888646c-5m6zh
Name:             cat-facts-app-5fc888646c-5m6zh
Namespace:        default
Priority:         0
Service Account:  default
Node:             drdk-cloud-assignment-control-plane/172.18.0.3
Start Time:       Sat, 09 Nov 2024 14:08:44 +0100
Labels:           app=cat-facts-app
                  pod-template-hash=5fc888646c
Annotations:      <none>
Status:           Pending
IP:               10.244.0.5
IPs:
  IP:           10.244.0.5
Controlled By:  ReplicaSet/cat-facts-app-5fc888646c
Containers:
  app:
    Container ID:
    Image:          cat-app:v1
    Image ID:
    Port:           8000/TCP
    Host Port:      0/TCP
    State:          Waiting
      Reason:       CreateContainerConfigError
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-r7jxd (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True
  Initialized                 True
  Ready                       False
  ContainersReady             False
  PodScheduled                True
Volumes:
  kube-api-access-r7jxd:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                  From               Message
  ----     ------     ----                 ----               -------
  Normal   Scheduled  27m                  default-scheduler  Successfully assigned default/cat-facts-app-5fc888646c-5m6zh to drdk-cloud-assignment-control-plane
  Warning  Failed     25m (x12 over 27m)   kubelet            Error: container has runAsNonRoot and image will run as root (pod: "cat-facts-app-5fc888646c-5m6zh_default(a34cc5d4-023d-42a0-8f60-9873719c6fe8)", container: app)    
  Normal   Pulled     86s (x117 over 27m)  kubelet            Container image "cat-app:v1" already present on machine


This shows that an error occurs because "container has runAsNonRoot and image will run as root" So either pod should not be run as non root or image should be set up to not run as root.

As the application doesn't require root privileges I modified the security context of the app and gave a non-root user id 1000. This removes root privileges from the app as it is not needed and will limit damage that can be done if an attacker gains access to container.

Now Kubernetes does not give root access to the app.
The Dockerfile does not specify user. So by default it would run as root user. By setting runAsUser: 1000 in k8s /deployment.yaml Kubernetes will override default behaviour and force container to run as UID 1000. 

added following lines to Dockerfile

# Change ownership of /app to the 'node' user
RUN chown -R node:node /app

# Set the user to the existing 'node' user for the rest of the container lifecycle
USER node
__
Then i build docker container with
$ docker build -t cat-app:v1 

and load the updated image to kind 
$kind load docker-image cat-app:v1

$ kubectl rollout restart deployment
deployment.apps/cat-facts-app restarted
$ kubectl get pods
NAME                             READY   STATUS        RESTARTS   AGE
cat-facts-app-6cdf655d65-htnrn   1/1     Terminating   0          48m
cat-facts-app-b6bb6cfc5-824cx    1/1     Running       0          8s

Now bug has been fixed!

______________________________________________________________________________________________

Build a Feature

The hardcoded URL should not be defined in the code. Environment variables makes more sense to use here as it externalizes the configuration and can be modified without changing source code. 

I create a configmap to create variable cat-facts-config. In this i detail the necessary key-value pairs for the app config. this includes CAT_API_URL which uses the hardcoded url. Then i update deployment to include the new cat-facts-config with valuefrom CAT_API-URL.

This i then use in the code getting as process.env.CAT_API_URL; 

Then I now try to portforward my service so i can use it with 
$ kubectl port-forward pod/cat-facts-app-6fbd5b5df-lb687 8000:8000

when going to localhost:8000/random-cat-fact i get 
{"error":"An error occurred while fetching the cat fact"}

i try to visit the url to find out it doesn't work... 
Application error
An error occurred in the application and your page could not be served. If you are the application owner, check your logs for details. You can do this from the Heroku CLI with the command
heroku logs --tail

I replace the url with https://catfact.ninja/fact? as this also provides cat facts.
 




